import openai
import os
import asyncio
import logging
import json

# Set up logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# Set up OpenAI API key
openai.api_key = os.getenv("OPENAI_API_KEY")
if not openai.api_key:
    logging.error("OPENAI_API_KEY is not set in the environment variables.")
    exit(1)

async def generate_response(prompt, model, max_tokens=100, temperature=0.7):
    try:
        response = await openai.Completion.create(
            engine=model,
            prompt=prompt,
            max_tokens=max_tokens,
            n=1,
            stop=None,
            temperature=temperature,
        )
        return response.choices[0].text.strip()
    except Exception as e:
        logging.error(f"Error generating response: {e}")
        return None

async def auto_trainer(prompts, base_model, max_tokens=100, temperature=0.7):
    training_data = []
    for prompt in prompts:
        gpt3_5_response, gpt4_response = await asyncio.gather(
            generate_response(prompt, "text-davinci-002", max_tokens, temperature),
            generate_response(prompt, "text-davinci-003", max_tokens, temperature)
        )
        
        if gpt3_5_response and gpt4_response:
            training_data.append({
                "prompt": prompt,
                "completion": gpt4_response  # Assuming we want to fine-tune towards GPT-4 responses
            })
        else:
            logging.warning(f"Skipping prompt due to error: {prompt}")

    # Convert training data to JSONL format
    with open("training_data.jsonl", "w") as f:
        for item in training_data:
            f.write(json.dumps(item) + "\n")

    # Upload the file to OpenAI and fine-tune the model
    try:
        file = openai.File.create(file=open("training_data.jsonl"), purpose='fine-tune')
        fine_tuned_model = openai.FineTune.create(
            training_file=file.id,
            model=base_model,
            n_epochs=4,
            batch_size=2,
            learning_rate_multiplier=0.1,
        )
        return fine_tuned_model
    except Exception as e:
        logging.error(f"Error during fine-tuning: {e}")
        return None

# Example usage
prompts = [
    "What is the capital of France?",
    "Explain the concept of machine learning.",
    "Write a short story about a magical adventure.",
]

base_model = "text-davinci-002"

# Run the auto trainer asynchronously
loop = asyncio.get_event_loop()
fine_tuned_model = loop.run_until_complete(auto_trainer(prompts, base_model))
print(f"Fine-tuned model: {fine_tuned_model}")
